
ðŸ¥” Potato Disease Classification
Dataset credits: https://www.kaggle.com/arjuntejaswi/plant-village

I. Importing Librairies
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
We first use the splitfolder library to split our raw data into 3 datasets: the training (80%), validation (10%) and the testing dataset (10%).

splitfolders --output ../data/dataset --ratio 0.7 0.1 0.2 -- ../data/raw/PlantVillage/

Seting up all the Constants

BATCH_SIZE=32
IMAGE_SIZE=256
CHANNELS=3
EPOCHS=20
train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,
        horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
        '../data/dataset/train',
        target_size=(IMAGE_SIZE, IMAGE_SIZE),
        batch_size=BATCH_SIZE,
        class_mode="sparse",
)
Found 1506 images belonging to 3 classes.
class_names = list(train_generator.class_indices.keys())
class_names
['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']
validation_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,
        horizontal_flip=True)

validation_generator = validation_datagen.flow_from_directory(
        '../data/dataset/val',
        target_size=(IMAGE_SIZE,IMAGE_SIZE),
        batch_size=32,
        class_mode="sparse"
)
Found 215 images belonging to 3 classes.
test_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,
        horizontal_flip=True)

test_generator = test_datagen.flow_from_directory(
        '../data/dataset/test',
        target_size=(IMAGE_SIZE,IMAGE_SIZE),
        batch_size=32,
        class_mode="sparse"
)
Found 431 images belonging to 3 classes.
Let's visualize some of the images from our dataset

plt.figure(figsize=(12,4))

for image_batch, label_batch in train_generator:
    plt.imshow(image_batch[0])
    plt.title(class_names[int(label_batch[0])])
    plt.axis("off")
    break

II. Model Building
We will use a CNN coupled with a Softmax activation in the output layer.

input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 3

model = models.Sequential([
    layers.InputLayer(input_shape=input_shape),
    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(n_classes, activation='softmax'),
])
model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 254, 254, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         
 2D)                                                             
                                                                 
 conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 256)               0         
                                                                 
 dense (Dense)               (None, 64)                16448     
                                                                 
 dense_1 (Dense)             (None, 3)                 195       
                                                                 
=================================================================
Total params: 183,747
Trainable params: 183,747
Non-trainable params: 0
_________________________________________________________________
Let's compile the model
We use adam optimizer, SparseCategoricalCrossentropyfor losses and accuracy as a metric.

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)
history = model.fit(
    train_generator,
    steps_per_epoch=47,
    batch_size=BATCH_SIZE,
    validation_data=validation_generator,
    validation_steps=6,
    verbose=1,
    epochs=EPOCHS,
)
Epoch 1/20
47/47 [==============================] - 107s 2s/step - loss: 0.8930 - accuracy: 0.4668 - val_loss: 0.8275 - val_accuracy: 0.5156
Epoch 2/20
47/47 [==============================] - 103s 2s/step - loss: 0.7403 - accuracy: 0.6058 - val_loss: 0.6937 - val_accuracy: 0.6146
Epoch 3/20
47/47 [==============================] - 104s 2s/step - loss: 0.5021 - accuracy: 0.7707 - val_loss: 0.4635 - val_accuracy: 0.7865
Epoch 4/20
47/47 [==============================] - 102s 2s/step - loss: 0.4145 - accuracy: 0.8195 - val_loss: 0.3360 - val_accuracy: 0.8594
Epoch 5/20
47/47 [==============================] - 102s 2s/step - loss: 0.3375 - accuracy: 0.8609 - val_loss: 0.3531 - val_accuracy: 0.8333
Epoch 6/20
47/47 [==============================] - 104s 2s/step - loss: 0.2567 - accuracy: 0.8930 - val_loss: 0.2555 - val_accuracy: 0.8958
Epoch 7/20
47/47 [==============================] - 102s 2s/step - loss: 0.2169 - accuracy: 0.9084 - val_loss: 0.1849 - val_accuracy: 0.9219
Epoch 8/20
47/47 [==============================] - 102s 2s/step - loss: 0.1878 - accuracy: 0.9193 - val_loss: 0.2422 - val_accuracy: 0.8958
Epoch 9/20
47/47 [==============================] - 103s 2s/step - loss: 0.1705 - accuracy: 0.9308 - val_loss: 0.1717 - val_accuracy: 0.9271
Epoch 10/20
47/47 [==============================] - 102s 2s/step - loss: 0.2002 - accuracy: 0.9186 - val_loss: 0.2114 - val_accuracy: 0.9323
Epoch 11/20
47/47 [==============================] - 103s 2s/step - loss: 0.1346 - accuracy: 0.9471 - val_loss: 0.1312 - val_accuracy: 0.9479
Epoch 12/20
47/47 [==============================] - 103s 2s/step - loss: 0.1272 - accuracy: 0.9471 - val_loss: 0.1974 - val_accuracy: 0.9323
Epoch 13/20
47/47 [==============================] - 102s 2s/step - loss: 0.1555 - accuracy: 0.9355 - val_loss: 0.1978 - val_accuracy: 0.9167
Epoch 14/20
47/47 [==============================] - 102s 2s/step - loss: 0.1132 - accuracy: 0.9573 - val_loss: 0.1056 - val_accuracy: 0.9479
Epoch 15/20
47/47 [==============================] - 104s 2s/step - loss: 0.1021 - accuracy: 0.9548 - val_loss: 0.1431 - val_accuracy: 0.9427
Epoch 16/20
47/47 [==============================] - 102s 2s/step - loss: 0.0783 - accuracy: 0.9735 - val_loss: 0.0931 - val_accuracy: 0.9688
Epoch 17/20
47/47 [==============================] - 102s 2s/step - loss: 0.0708 - accuracy: 0.9749 - val_loss: 0.0894 - val_accuracy: 0.9688
Epoch 18/20
47/47 [==============================] - 102s 2s/step - loss: 0.0543 - accuracy: 0.9749 - val_loss: 0.0575 - val_accuracy: 0.9688
Epoch 19/20
47/47 [==============================] - 102s 2s/step - loss: 0.0863 - accuracy: 0.9668 - val_loss: 0.2317 - val_accuracy: 0.8958
Epoch 20/20
47/47 [==============================] - 102s 2s/step - loss: 0.0950 - accuracy: 0.9620 - val_loss: 0.0950 - val_accuracy: 0.9635
scores = model.evaluate(test_generator)
14/14 [==============================] - 23s 2s/step - loss: 0.1181 - accuracy: 0.9559
ðŸ“ˆ Plotting the Accuracy and Loss Curves

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(EPOCHS), acc, label='Training Accuracy')
plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(EPOCHS), loss, label='Training Loss')
plt.plot(range(EPOCHS), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

III. Prediction on a sample image
import numpy as np

for image_batch, label_batch in test_generator:

    first_image = image_batch[0]
    first_label = int(label_batch[0])
    
    print("First image to predict")
    plt.imshow(first_image)
    print(f"Actual label: {class_names[first_label]}")
    
    batch_prediction = model.predict(image_batch)
    print(f"Predicted label: {class_names[np.argmax(batch_prediction[0])]}")
    
    break
First image to predict
Actual label: Potato___Late_blight
1/1 [==============================] - 1s 670ms/step
Predicted label: Potato___Late_blight

Let's write a function for inference

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence
plt.figure(figsize=(15, 15))

for images, labels in test_generator:
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i])
        
        predicted_class, confidence = predict(model, images[i])
        actual_class = class_names[int(labels[i])] 
        
        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")
        
        plt.axis("off")
    break
1/1 [==============================] - 0s 259ms/step
1/1 [==============================] - 0s 93ms/step
1/1 [==============================] - 0s 43ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 37ms/step

IV. Saving the Model
model.save("../models/potatoes.h5")
